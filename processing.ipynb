{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> CS F320 Foundations of Data Science <center>\n",
    "\n",
    "## <center> Assignment <center>\n",
    "\n",
    "***\n",
    "\n",
    "### Group 8\n",
    "\n",
    "#### 1. 2022A7PS0145P - Armaan Gupta\n",
    "#### 2. 2022A7PS0065P - Animish Tiwari\n",
    "#### 3. 2022A7PS0164P - Anjaneya Bajaj\n",
    "#### 4. 2022A7PS0120P - Aryan Jain\n",
    "\n",
    "***\n",
    "\n",
    "#### Dataset : [Electrical Grid Stability Simulated Data](https://archive.ics.uci.edu/dataset/471/electrical+grid+stability+simulated+data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, precision_score, recall_score, f1_score, silhouette_score, pairwise_distances, confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from ngboost import NGBRegressor\n",
    "from tabulate import tabulate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from scipy.spatial.distance import pdist, squareform, cdist\n",
    "from scipy.stats import pearsonr\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import optuna\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the dataset and pre-processing\n",
    "\n",
    "- We will first load in the dataset and take a look at the first few rows to understand the data better.\n",
    "- We will then check for any missing values - there are none.\n",
    "- As per the question, we will drop categorical columns - there are None.\n",
    "- Eliminating outliers - any value that is more than 3 standard deviations away from the mean will be considered an outlier and will be removed.\n",
    "- Making plots to visualize the data distributions.\n",
    "- Seperating the two target variables one for classification and one for regression.\n",
    "- Splitting the data into training and testing sets.\n",
    "- Applying PCA, taking 10 principal components to account for >95% variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "electrical_grid_stability_simulated_data = fetch_ucirepo(id=471) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = electrical_grid_stability_simulated_data.data.features \n",
    "y = electrical_grid_stability_simulated_data.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(electrical_grid_stability_simulated_data.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(electrical_grid_stability_simulated_data.variables) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution of all numeric columns\n",
    "\n",
    "numeric_columns = df.drop(columns=['stab', 'stabf']).columns\n",
    "\n",
    "num_plots = len(numeric_columns)\n",
    "num_cols = 3\n",
    "num_rows = (num_plots // num_cols) + (1 if num_plots % num_cols != 0 else 0) \n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(16, 6*num_rows))\n",
    "axes = axes.flatten()  \n",
    "\n",
    "for i, col in enumerate(numeric_columns):\n",
    "    sns.histplot(df[col], kde=True, ax=axes[i])\n",
    "    axes[i].set_title(f'Distribution of {col}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for variable 'stab'\n",
    "\n",
    "sns.histplot(df['stab'], kde=True)\n",
    "plt.title('Distribution of stab')\n",
    "plt.xlabel('stab')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for variable 'stabf'\n",
    "\n",
    "sns.countplot(x='stabf', data=df)\n",
    "plt.title('Distribution of stabf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into features and target\n",
    "\n",
    "X = df.drop(['stab', 'stabf'], axis=1)\n",
    "y = df['stab']\n",
    "y_classification = df['stabf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing outliers in all columns\n",
    "\n",
    "X = X[(np.abs(stats.zscore(X)) < 3).all(axis=1)] \n",
    "y = y[(np.abs(stats.zscore(y)) < 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the train and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_classification, X_test_classification, y_train_classification, y_test_classification = train_test_split(X, y_classification, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the labels\n",
    "y_train_classification_encoded = label_encoder.fit_transform(y_train_classification)\n",
    "y_test_classification_encoded = label_encoder.transform(y_test_classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, class_ in enumerate(label_encoder.classes_):\n",
    "    print(f'{class_} -> {i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-Score transformation\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# PCA \n",
    "\n",
    "# pca = PCA(n_components=3)\n",
    "pca = PCA()\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-Score transformation\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_classification_scaled = scaler.fit_transform(X_train_classification)\n",
    "X_test_classification_scaled = scaler.transform(X_test_classification)\n",
    "\n",
    "# PCA \n",
    "\n",
    "# pca = PCA(n_components=3)\n",
    "pca = PCA()\n",
    "X_train_classification_pca = pca.fit_transform(X_train_classification_scaled)\n",
    "X_test_classification_pca = pca.transform(X_test_classification_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explained variance ratio\n",
    "\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "# Plotting scree plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, len(explained_variance) + 1), explained_variance, marker='o', linestyle='--')\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_variance = pca.explained_variance_ratio_.cumsum()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', linestyle='--')\n",
    "plt.title('Cumulative Explained Variance')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.axhline(y=0.95, color='r', linestyle='--', label='95% Variance')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on plots, extracting 10 principal components\n",
    "\n",
    "X_train_pca = X_train_pca[:, :10]\n",
    "X_test_pca = X_test_pca[:, :10]\n",
    "\n",
    "X_train_classification_pca = X_train_classification_pca[:, :10]\n",
    "X_test_classification_pca = X_test_classification_pca[:, :10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Models\n",
    "\n",
    "Applying various regression models and calculating RMSE and MAE for each model. Models applied :\n",
    "- Linear Regression\n",
    "- Random Forests\n",
    "- Extra Random Trees\n",
    "- AdaBoost\n",
    "- XGBoost\n",
    "- NGBoost\n",
    "- Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "            \"Linear Regression\",\n",
    "            \"Ridge Regression\",\n",
    "            \"Lasso Regression\",\n",
    "            \"Elastic Net\",\n",
    "            \"Random Forest\",\n",
    "            \"Extra Trees\",\n",
    "            \"AdaBoost\",\n",
    "            \"XGBoost\",\n",
    "            \"NGBoost\"\n",
    "         ]\n",
    "\n",
    "# Objective function for Optuna hyperparameter tuning\n",
    "def objective(trial, model_name, X_train, y_train):\n",
    "    if model_name == \"Linear Regression\":\n",
    "        model = LinearRegression()\n",
    "    elif model_name == \"Ridge Regression\":\n",
    "        model = Ridge(\n",
    "            alpha=trial.suggest_float(\"alpha\", 1e-4, 100.0, log=True),\n",
    "            max_iter=trial.suggest_int(\"max_iter\", 100, 2000)\n",
    "        )\n",
    "    elif model_name == \"Lasso Regression\":\n",
    "        model = Lasso(\n",
    "            alpha=trial.suggest_float(\"alpha\", 1e-4, 100.0, log=True),  \n",
    "            max_iter=trial.suggest_int(\"max_iter\", 100, 2000)           \n",
    "        )\n",
    "    elif model_name == \"Elastic Net\":\n",
    "        model = ElasticNet(\n",
    "            alpha=trial.suggest_float(\"alpha\", 1e-4, 100.0, log=True),  \n",
    "            l1_ratio=trial.suggest_float(\"l1_ratio\", 0.0, 1.0),         \n",
    "            max_iter=trial.suggest_int(\"max_iter\", 100, 2000)           \n",
    "        )\n",
    "    elif model_name == \"Random Forest\":\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=trial.suggest_int(\"n_estimators\", 50, 500),\n",
    "            max_depth=trial.suggest_int(\"max_depth\", 3, 20),\n",
    "            min_samples_split=trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "            min_samples_leaf=trial.suggest_int(\"min_samples_leaf\", 1, 20),\n",
    "            random_state=42,\n",
    "        )\n",
    "    elif model_name == \"Extra Trees\":\n",
    "        model = ExtraTreesRegressor(\n",
    "            n_estimators=trial.suggest_int(\"n_estimators\", 50, 500),\n",
    "            max_depth=trial.suggest_int(\"max_depth\", 3, 20),\n",
    "            min_samples_split=trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "            min_samples_leaf=trial.suggest_int(\"min_samples_leaf\", 1, 20),\n",
    "            random_state=42,\n",
    "        )\n",
    "    elif model_name == \"AdaBoost\":\n",
    "        model = AdaBoostRegressor(\n",
    "            n_estimators=trial.suggest_int(\"n_estimators\", 50, 500),\n",
    "            learning_rate=trial.suggest_float(\"learning_rate\", 0.001, 1.0),\n",
    "            random_state=42,\n",
    "        )\n",
    "    elif model_name == \"XGBoost\":\n",
    "        model = XGBRegressor(\n",
    "            n_estimators=trial.suggest_int(\"n_estimators\", 50, 500),\n",
    "            max_depth=trial.suggest_int(\"max_depth\", 3, 20),\n",
    "            learning_rate=trial.suggest_float(\"learning_rate\", 0.01, 1),\n",
    "            colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "            random_state=42,\n",
    "            objective='reg:squarederror',\n",
    "        )\n",
    "    elif model_name == \"NGBoost\":\n",
    "        model = NGBRegressor(\n",
    "            n_estimators=trial.suggest_int(\"n_estimators\", 50, 500),\n",
    "            learning_rate=trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "            random_state=42,\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model_name}\")\n",
    "\n",
    "    # Cross-validation to evaluate performance\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "    return np.sqrt(-scores.mean())\n",
    "\n",
    "# Function to tune models using Optuna\n",
    "def tune_model(model_name, X_train, y_train):\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(lambda trial: objective(trial, model_name, X_train, y_train), n_trials=1)\n",
    "    return study.best_params, study.best_value\n",
    "\n",
    "# Function to train models with the best hyperparameters\n",
    "def train_model_with_best_params(model_name, best_params, X_train, y_train):\n",
    "    if model_name == \"Linear Regression\":\n",
    "        model = LinearRegression()\n",
    "    elif model_name == \"Ridge Regression\":\n",
    "        model = Ridge(**best_params)\n",
    "    elif model_name == \"Lasso Regression\":\n",
    "        model = Lasso(**best_params)\n",
    "    elif model_name == \"Elastic Net\":\n",
    "        model = ElasticNet(**best_params)\n",
    "    elif model_name == \"Random Forest\":\n",
    "        model = RandomForestRegressor(**best_params)\n",
    "    elif model_name == \"Extra Trees\":\n",
    "        model = ExtraTreesRegressor(**best_params)\n",
    "    elif model_name == \"AdaBoost\":\n",
    "        model = AdaBoostRegressor(**best_params)\n",
    "    elif model_name == \"XGBoost\":\n",
    "        model = XGBRegressor(**best_params)\n",
    "    elif model_name == \"NGBoost\":\n",
    "        model = NGBRegressor(**best_params)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model_name}\")\n",
    "    \n",
    "    print(f\"Training {model_name} with best hyperparameters...\")\n",
    "    print(f\"Best hyperparameters: {best_params}\")\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def plot_predicted_vs_actual(y_pred, y_test, model_name, image_path):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(\n",
    "        y_test, y_pred, \n",
    "        alpha=0.6, color=\"blue\", marker='o', label=\"Predicted Values\"\n",
    "    )\n",
    "\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "             \"r--\", label=\"Ideal: Predicted = Actual\")\n",
    "\n",
    "    plt.title(f\"Predicted vs Actual Values: {model_name}\")\n",
    "    plt.xlabel(\"Actual Values\")\n",
    "    plt.ylabel(\"Predicted Values\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    if os.path.exists(image_path) == False:\n",
    "        os.makedirs(image_path)\n",
    "    plot_name = os.path.join(image_path, f\"{model_name}_regression.png\")\n",
    "    plt.savefig(plot_name)\n",
    "    print(f\"Predicted vs Actual plot saved as: {plot_name}\")\n",
    "    plt.close()\n",
    "\n",
    "# Train models with optimized parameters and evaluate them\n",
    "def regression_models_optimized(X_train, X_test, y_train, y_test, models, image_path):\n",
    "    model_results = []\n",
    "    model_params = []\n",
    "    for model_name in models:\n",
    "        print(f\"Tuning hyperparameters for {model_name}...\")\n",
    "        best_params, best_score = tune_model(model_name, X_train, y_train)\n",
    "        print(f\"Best parameters for {model_name}: {best_params}\")\n",
    "        \n",
    "        # Train the model with the best parameters\n",
    "        tuned_model = train_model_with_best_params(model_name, best_params, X_train, y_train)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        y_pred = tuned_model.predict(X_test)\n",
    "        \n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        \n",
    "        plot_predicted_vs_actual(y_pred, y_test, model_name, image_path)\n",
    "\n",
    "        model_results.append({\"Model\": model_name, \"RMSE\": rmse, \"MAE\": mae})\n",
    "        model_params.append({\"Model\": model_name, \"Best Parameters\": best_params})\n",
    "    \n",
    "    results_df = pd.DataFrame(model_results)\n",
    "    params_df = pd.DataFrame(model_params)\n",
    "    return results_df, params_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate models with optimized hyperparameters\n",
    "results_original, params_original = regression_models_optimized(X_train, X_test, y_train, y_test, models, \"./original_regression_plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pca, params_pca = regression_models_optimized(X_train_pca, X_test_pca, y_train, y_test, models, \"./pca_regression_plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Regression Models Evaluation on Original Dataset\\n\")\n",
    "print(tabulate(results_original, headers=[\"Model\", \"RMSE\", \"MAE\"], tablefmt=\"grid\"))\n",
    "print(\"\\nBest Hyperparameters for Original Dataset\\n\")\n",
    "print(tabulate(params_original, headers=\"keys\", tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Regresssion Models Evaluation on PCA Dataset\\n\")\n",
    "print(tabulate(results_pca, headers=[\"Model\", \"RMSE\", \"MAE\"], tablefmt=\"grid\"))\n",
    "print(\"\\nBest Hyperparameters for PCA Dataset\\n\")\n",
    "print(tabulate(params_pca, headers=\"keys\", tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Models\n",
    "\n",
    "Applying various classification models and calculating accuracy, precision, recall and F1-score for each model. Models applied :\n",
    "- Logistic Regression\n",
    "- Naive Bayes\n",
    "- KNN\n",
    "- Linear SVM\n",
    "- Kernel SVM\n",
    "- Decision Trees\n",
    "- 2 Layer Fully Connected Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "            \"Logistic Regression with L1 Regularization\",\n",
    "            \"Logistic Regression with L2 Regularization\",\n",
    "            \"Logistic Regression with Elastic Net Regularization\",\n",
    "            \"Gaussian Naive Bayes\",\n",
    "            \"K-Nearest Neighbors\",\n",
    "            \"Linear SVM\",\n",
    "            \"Kernel SVM\",\n",
    "            \"Decision Tree\"\n",
    "         ]\n",
    "\n",
    "# Objective function for Optuna hyperparameter tuning (Classification)\n",
    "def objective(trial, model_name, X_train, y_train):\n",
    "    if model_name == \"Logistic Regression with L1 Regularization\":\n",
    "        model = LogisticRegression(\n",
    "            penalty=\"l1\",\n",
    "            solver=\"liblinear\",  # 'liblinear' supports L1 regularization\n",
    "            C=trial.suggest_float(\"C\", 1e-4, 10.0, log=True),\n",
    "            max_iter=trial.suggest_int(\"max_iter\", 100, 2000),\n",
    "            random_state=42,\n",
    "        )\n",
    "    elif model_name == \"Logistic Regression with L2 Regularization\":\n",
    "        model = LogisticRegression(\n",
    "            penalty=\"l2\",\n",
    "            solver=\"lbfgs\",\n",
    "            C=trial.suggest_float(\"C\", 1e-4, 10.0, log=True),\n",
    "            max_iter=trial.suggest_int(\"max_iter\", 100, 2000),\n",
    "            random_state=42,\n",
    "        )\n",
    "    elif model_name == \"Logistic Regression with Elastic Net Regularization\":\n",
    "        model = LogisticRegression(\n",
    "            penalty=\"elasticnet\",\n",
    "            solver=\"saga\",  # 'saga' supports Elastic Net\n",
    "            C=trial.suggest_float(\"C\", 1e-4, 10.0, log=True),\n",
    "            l1_ratio=trial.suggest_float(\"l1_ratio\", 0.0, 1.0),\n",
    "            max_iter=trial.suggest_int(\"max_iter\", 100, 2000),\n",
    "            random_state=42,\n",
    "        )\n",
    "    elif model_name == \"Gaussian Naive Bayes\":\n",
    "        model = GaussianNB()\n",
    "    elif model_name == \"K-Nearest Neighbors\":\n",
    "        model = KNeighborsClassifier(\n",
    "            n_neighbors=trial.suggest_int(\"n_neighbors\", 1, 50),\n",
    "            weights=trial.suggest_categorical(\"weights\", [\"uniform\", \"distance\"]),\n",
    "            p=trial.suggest_int(\"p\", 1, 2),  # Minkowski metric: 1 for Manhattan, 2 for Euclidean\n",
    "        )\n",
    "    elif model_name == \"Linear SVM\":\n",
    "        model = SVC(\n",
    "            kernel=\"linear\",\n",
    "            C=trial.suggest_float(\"C\", 1e-4, 10.0, log=True),\n",
    "            random_state=42,\n",
    "        )\n",
    "    elif model_name == \"Kernel SVM\":\n",
    "        model = SVC(\n",
    "            kernel=\"rbf\",\n",
    "            C=trial.suggest_float(\"C\", 1e-4, 10.0, log=True),\n",
    "            gamma=trial.suggest_float(\"gamma\", 1e-4, 10.0, log=True),\n",
    "            random_state=42,\n",
    "        )\n",
    "    elif model_name == \"Decision Tree\":\n",
    "        model = DecisionTreeClassifier(\n",
    "            max_depth=trial.suggest_int(\"max_depth\", 1, 20),\n",
    "            min_samples_split=trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "            min_samples_leaf=trial.suggest_int(\"min_samples_leaf\", 1, 20),\n",
    "            random_state=42,\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model_name}\")\n",
    "\n",
    "    # Cross-validation to evaluate performance\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "    return scores.mean()\n",
    "\n",
    "# Function to tune models using Optuna\n",
    "def tune_model(model_name, X_train, y_train):\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(lambda trial: objective(trial, model_name, X_train, y_train), n_trials=1)\n",
    "    return study.best_params, study.best_value\n",
    "\n",
    "# Function to train models with the best hyperparameters\n",
    "def train_model_with_best_params(model_name, best_params, X_train, y_train):\n",
    "    if model_name == \"Logistic Regression with L1 Regularization\":\n",
    "        model = LogisticRegression(penalty=\"l1\", solver=\"liblinear\", random_state=42, **best_params)\n",
    "    elif model_name == \"Logistic Regression with L2 Regularization\":\n",
    "        model = LogisticRegression(penalty=\"l2\", solver=\"lbfgs\", random_state=42, **best_params)\n",
    "    elif model_name == \"Logistic Regression with Elastic Net Regularization\":\n",
    "        model = LogisticRegression(penalty=\"elasticnet\", solver=\"saga\", random_state=42, **best_params)\n",
    "    elif model_name == \"Gaussian Naive Bayes\":\n",
    "        model = GaussianNB()\n",
    "    elif model_name == \"K-Nearest Neighbors\":\n",
    "        model = KNeighborsClassifier(**best_params)\n",
    "    elif model_name == \"Linear SVM\":\n",
    "        model = SVC(kernel=\"linear\", random_state=42, **best_params)\n",
    "    elif model_name == \"Kernel SVM\":\n",
    "        model = SVC(kernel=\"rbf\", random_state=42, **best_params)\n",
    "    elif model_name == \"Decision Tree\":\n",
    "        model = DecisionTreeClassifier(random_state=42, **best_params)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model_name}\")\n",
    "    \n",
    "    print(f\"Training {model_name} with best hyperparameters...\")\n",
    "    print(f\"Best hyperparameters: {best_params}\")\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def plot_confusion_matrix(y_pred, y_test, model_name, image_path):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "    plt.title(f\"Confusion Matrix: {model_name}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "\n",
    "    if os.path.exists(image_path) == False:\n",
    "        os.makedirs(image_path)\n",
    "    plot_name = os.path.join(image_path, f\"{model_name}_confusion_matrix.png\")\n",
    "    plt.savefig(plot_name)\n",
    "    print(f\"Confusion matrix saved as: {plot_name}\")\n",
    "    plt.close()\n",
    "    \n",
    "# Train models with optimized parameters and evaluate them\n",
    "def classification_models_optimized(X_train, X_test, y_train, y_test, models, image_path):\n",
    "    model_results = []\n",
    "    model_params = []\n",
    "    for model_name in models:\n",
    "        print(f\"Tuning hyperparameters for {model_name}...\")\n",
    "        best_params, best_score = tune_model(model_name, X_train, y_train)\n",
    "        print(f\"Best parameters for {model_name}: {best_params}\")\n",
    "        \n",
    "        # Train the model with the best parameters\n",
    "        tuned_model = train_model_with_best_params(model_name, best_params, X_train, y_train)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        y_pred = tuned_model.predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "        recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "        f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "        plot_confusion_matrix(y_pred, y_test, model_name, image_path)\n",
    "        model_results.append({\"Model\": model_name, \"Accuracy\": accuracy, \"Precision\": precision, \"Recall\": recall, \"F1-Score\": f1})\n",
    "        model_params.append({\"Model\": model_name, \"Best Parameters\": best_params})\n",
    "    \n",
    "    results_df = pd.DataFrame(model_results)\n",
    "    params_df = pd.DataFrame(model_params)\n",
    "    return results_df, params_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_original, params_original = classification_models_optimized(X_train_classification, X_test_classification, y_train_classification, y_test_classification, models, \"./original_classification_plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pca, params_pca = classification_models_optimized(X_train_classification_pca, X_test_classification_pca, y_train_classification, y_test_classification, models, \"./pca_classification_plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(BinaryNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        # return self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "def train_model(model, X_train, y_train, criterion, optimizer, batch_size, num_epochs):\n",
    "    model.train()\n",
    "    dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    loss_history = [] \n",
    "    accuracy_history = [] \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_X, batch_y in data_loader:\n",
    "            # Forward pass\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs.squeeze(), batch_y.float())\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item() * batch_X.size(0)  # Accumulate total loss\n",
    "            predictions = (torch.sigmoid(outputs.squeeze()) > 0.5).long()\n",
    "            correct += (predictions == batch_y).sum().item()\n",
    "            total += batch_y.size(0)\n",
    "        \n",
    "        # Calculate average loss and accuracy for the epoch\n",
    "        avg_loss = epoch_loss / len(data_loader.dataset)\n",
    "        accuracy = correct / total\n",
    "        \n",
    "        loss_history.append(avg_loss)\n",
    "        accuracy_history.append(accuracy)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    return loss_history, accuracy_history\n",
    "\n",
    "def plot_loss_vs_epochs(loss_history, model_name, image_path):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(range(1, len(loss_history) + 1), loss_history, label=\"Loss\", color=\"blue\")\n",
    "    plt.title(f\"Loss vs Epochs for {model_name}\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    if os.path.exists(image_path) == False:\n",
    "        os.makedirs(image_path)\n",
    "    plot_name = os.path.join(image_path, f\"{model_name}_loss_vs_epochs.png\")\n",
    "    plt.savefig(plot_name)\n",
    "    plt.close()\n",
    "\n",
    "def plot_accuracy_vs_epochs(accuracy_history, model_name, image_path):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(range(1, len(accuracy_history) + 1), accuracy_history, label=\"Accuracy\", color=\"green\")\n",
    "    plt.title(f\"Accuracy vs Epochs for {model_name}\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    if os.path.exists(image_path) == False:\n",
    "        os.makedirs(image_path)\n",
    "    plot_name = os.path.join(image_path, f\"{model_name}_accuracy_vs_epochs.png\")\n",
    "    plt.savefig(plot_name)\n",
    "    plt.close()\n",
    "\n",
    "def test_model(model, X_test, y_test, image_path, make_plot=False):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # y_pred = (model(X_test).squeeze() > 0.5).numpy()\n",
    "        logits = model(X_test).squeeze()  # Get logits\n",
    "        probabilities = torch.sigmoid(logits)  # Convert to probabilities\n",
    "        y_pred = (probabilities > 0.5).numpy()  # Threshold to get binary predictions\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    if (make_plot) :\n",
    "        plot_confusion_matrix(y_pred, y_test, \"Neural Network\", image_path)\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "def objective(trial, X_train, y_train, X_test, y_test, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor):\n",
    "    input_size = X_train.shape[1]\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 16, 128, step=16)\n",
    "    learning_rate = trial.suggest_float(\"lr\", 1e-4, 1e-1, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 128])\n",
    "    num_epochs = trial.suggest_int(\"num_epochs\", 50, 300, step=50)\n",
    "    \n",
    "    # Initialize the model, criterion, and optimizer\n",
    "    model = BinaryNN(input_size, hidden_size)\n",
    "    # criterion = nn.BCELoss()\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Train the model\n",
    "    train_model(model, X_train_tensor, y_train_tensor, criterion, optimizer, batch_size, num_epochs)\n",
    "    \n",
    "    # Test the model\n",
    "    accuracy, _, _, _ = test_model(model, X_test_tensor, y_test_tensor)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "def tune_nn(X_train, y_train, X_test, y_test, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, results, best_params_df, image_path):\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(lambda trial: objective(trial, X_train, y_train, X_test, y_test, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor), n_trials=1)\n",
    "    \n",
    "    best_params = study.best_params\n",
    "    print(\"Best hyperparameters:\", best_params)\n",
    "    \n",
    "    # Train the best model\n",
    "    input_size = X_train.shape[1]\n",
    "    model = BinaryNN(input_size, best_params[\"hidden_size\"])\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=best_params[\"lr\"])\n",
    "    \n",
    "    # Train and evaluate the model\n",
    "    loss_history, accuracy_history = train_model(model, X_train_tensor, y_train_tensor, criterion, optimizer, best_params[\"batch_size\"], best_params[\"num_epochs\"])\n",
    "    accuracy, precision, recall, f1 = test_model(model, X_test_tensor, y_test_tensor, image_path, make_plot=True)\n",
    "    \n",
    "    plot_loss_vs_epochs(loss_history, \"Neural Network\", image_path)\n",
    "    plot_accuracy_vs_epochs(accuracy_history, \"Neural Network\", image_path)\n",
    "    \n",
    "    print(\"Final Model Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1-Score: {f1:.2f}\")\n",
    "    \n",
    "    results.loc[len(results)] = [\"Neural Network\", accuracy, precision, recall, f1]\n",
    "    best_params_df.loc[len(best_params_df)] = [\"Neural Network\", best_params]\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to tensors\n",
    "X_train_tensor = torch.tensor(X_train_classification.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_classification_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test_classification.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_classification_encoded, dtype=torch.long)\n",
    "\n",
    "tune_nn(X_train_classification, y_train_classification, X_test_classification, y_test_classification, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, results_original, params_original, \"./original_classification_plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to tensors\n",
    "X_train_tensor = torch.tensor(X_train_classification_pca, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_classification_encoded, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test_classification_pca, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_classification_encoded, dtype=torch.long)\n",
    "\n",
    "tune_nn(X_train_classification_pca, y_train_classification, X_test_classification_pca, y_test_classification, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, results_pca, params_pca, \"./pca_classification_plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Models Evaluation on Original Dataset\\n\")\n",
    "print(tabulate(results_original, headers=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"], tablefmt=\"grid\"))\n",
    "print(\"\\nBest Hyperparameters for Original Dataset\\n\")\n",
    "print(tabulate(params_original, headers=\"keys\", tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Models Evaluation on PCA Dataset\\n\")\n",
    "print(tabulate(results_pca, headers=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"], tablefmt=\"grid\"))\n",
    "print(\"\\nBest Hyperparameters for PCA Dataset\\n\")\n",
    "print(tabulate(params_pca, headers=\"keys\", tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Models\n",
    "\n",
    "Scaling the original data.\n",
    "Applying various clustering models and calculating SSE, Silhouette, BetaCV, Dunn’s Index and Hubert’s Statistic for each model. Models applied :\n",
    "- KMeans\n",
    "- EM Clustering\n",
    "- KMedoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data \n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means_clustering(X, k):\n",
    "    kmeans = KMeans(n_clusters=k, init=\"k-means++\", random_state=42)\n",
    "    kmeans.fit(X)\n",
    "\n",
    "    return kmeans\n",
    "\n",
    "def em_clustering(X, k):\n",
    "    gmm = GaussianMixture(n_components=k, random_state=42)\n",
    "    gmm.fit(X)\n",
    "\n",
    "    return gmm\n",
    "\n",
    "def k_medoids_clustering(X, k):\n",
    "    kmedoids = KMedoids(n_clusters=k, random_state=42)\n",
    "    kmedoids.fit(X)\n",
    "\n",
    "    return kmedoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sse(X, model):\n",
    "    if isinstance(model, KMeans):\n",
    "        labels = model.labels_\n",
    "        centroids = model.cluster_centers_\n",
    "        sse = np.sum((X - centroids[labels]) ** 2)\n",
    "    elif isinstance(model, GaussianMixture):\n",
    "        labels = model.predict(X)\n",
    "        centroids = model.means_\n",
    "        sse = np.sum((X - centroids[labels]) ** 2)\n",
    "    elif isinstance(model, KMedoids):\n",
    "        labels = model.labels_\n",
    "        medoids = model.cluster_centers_\n",
    "        sse = np.sum((X - medoids[labels]) ** 2)\n",
    "    return sse\n",
    "\n",
    "def compute_silhouette(X, model):\n",
    "    if isinstance(model, KMeans):\n",
    "        labels = model.labels_\n",
    "    elif isinstance(model, GaussianMixture):\n",
    "        labels = model.predict(X)\n",
    "    elif isinstance(model, KMedoids):\n",
    "        labels = model.labels_\n",
    "    \n",
    "    return silhouette_score(X, labels)\n",
    "\n",
    "# def compute_dunn_index(X, model):\n",
    "#     if isinstance(model, KMeans):\n",
    "#         labels = model.labels_\n",
    "#     elif isinstance(model, GaussianMixture):\n",
    "#         labels = model.predict(X)\n",
    "#     elif isinstance(model, KMedoids):\n",
    "#         labels = model.labels_\n",
    "\n",
    "#     # Compute pairwise distances between points\n",
    "#     pairwise_dists = pairwise_distances(X)\n",
    "\n",
    "#     # Calculate intra-cluster distances (min distance within the same cluster)\n",
    "#     intra_cluster_distances = []\n",
    "#     for label in np.unique(labels):\n",
    "#         cluster_points = X[labels == label]\n",
    "#         if len(cluster_points) > 1:\n",
    "#             intra_cluster_distances.append(np.min(pairwise_distances(cluster_points)))\n",
    "#     min_intra_cluster_distance = np.min(intra_cluster_distances)\n",
    "\n",
    "#     # Calculate inter-cluster distances (min distance between different clusters)\n",
    "#     inter_cluster_distances = []\n",
    "#     for i, label1 in enumerate(np.unique(labels)):\n",
    "#         for j, label2 in enumerate(np.unique(labels)):\n",
    "#             if label1 != label2:\n",
    "#                 cluster1_points = X[labels == label1]\n",
    "#                 cluster2_points = X[labels == label2]\n",
    "#                 inter_cluster_distances.append(np.min(pairwise_distances(np.concatenate([cluster1_points, cluster2_points]))))\n",
    "#     max_inter_cluster_distance = np.max(inter_cluster_distances)\n",
    "\n",
    "#     return min_intra_cluster_distance / max_inter_cluster_distance\n",
    "\n",
    "# def compute_dunn_index(X, model):\n",
    "#     # Get labels based on the model type\n",
    "#     if isinstance(model, KMeans):\n",
    "#         labels = model.labels_\n",
    "#     elif isinstance(model, GaussianMixture):\n",
    "#         labels = model.predict(X)\n",
    "#     elif isinstance(model, KMedoids):\n",
    "#         labels = model.labels_\n",
    "\n",
    "#     # Compute pairwise distances between points\n",
    "#     pairwise_dists = pairwise_distances(X)\n",
    "\n",
    "#     # Calculate intra-cluster distances (min distance within the same cluster)\n",
    "#     intra_cluster_distances = []\n",
    "#     for label in np.unique(labels):\n",
    "#         cluster_points = X[labels == label]\n",
    "#         if len(cluster_points) > 1:\n",
    "#             # Compute pairwise distances within the cluster\n",
    "#             cluster_pairwise_dists = pairwise_distances(cluster_points)\n",
    "#             np.fill_diagonal(cluster_pairwise_dists, np.inf)  # Ignore the diagonal (distance to itself)\n",
    "#             min_intra_cluster_distance = np.min(cluster_pairwise_dists)\n",
    "#             intra_cluster_distances.append(min_intra_cluster_distance)\n",
    "#         else:\n",
    "#             # For a cluster with only one point, intra-cluster distance is 0\n",
    "#             intra_cluster_distances.append(0)\n",
    "    \n",
    "#     # If no intra-cluster distances were computed (i.e., all clusters are singletons), return NaN\n",
    "#     if not intra_cluster_distances:\n",
    "#         return np.nan\n",
    "    \n",
    "#     min_intra_cluster_distance = np.min(intra_cluster_distances)\n",
    "\n",
    "#     # Calculate inter-cluster distances (min distance between different clusters)\n",
    "#     inter_cluster_distances = []\n",
    "#     for i, label1 in enumerate(np.unique(labels)):\n",
    "#         for j, label2 in enumerate(np.unique(labels)):\n",
    "#             if label1 != label2:\n",
    "#                 cluster1_points = X[labels == label1]\n",
    "#                 cluster2_points = X[labels == label2]\n",
    "#                 # Compute pairwise distances between two clusters\n",
    "#                 dist = np.min(pairwise_distances(np.concatenate([cluster1_points, cluster2_points])))\n",
    "#                 inter_cluster_distances.append(dist)\n",
    "    \n",
    "#     # If no inter-cluster distances were computed, return NaN\n",
    "#     if not inter_cluster_distances:\n",
    "#         return np.nan\n",
    "\n",
    "#     max_inter_cluster_distance = np.max(inter_cluster_distances)\n",
    "\n",
    "#     # Avoid division by zero by checking if the max inter-cluster distance is greater than zero\n",
    "#     if max_inter_cluster_distance == 0:\n",
    "#         return np.nan\n",
    "\n",
    "#     return min_intra_cluster_distance / max_inter_cluster_distance\n",
    "\n",
    "def compute_dunn_index(X, labels):\n",
    "    unique_clusters = np.unique(labels)\n",
    "    num_clusters = len(unique_clusters)\n",
    "    max_intracluster_dist = 0.0\n",
    "    min_intercluster_dist = np.inf\n",
    "    # Calculate maximum intracluster distance\n",
    "    for i in unique_clusters:\n",
    "        cluster_i_points = X[labels == i]\n",
    "        # Handle clusters with single or no data points\n",
    "        if len(cluster_i_points) <= 1:\n",
    "            intracluster_dist = 0  # or any other appropriate value\n",
    "        else:\n",
    "            intracluster_dist = np.max(pdist(cluster_i_points))  \n",
    "       \n",
    "        if intracluster_dist > max_intracluster_dist:\n",
    "            max_intracluster_dist = intracluster_dist\n",
    "\n",
    "    # Calculate minimum intercluster distance\n",
    "    for i in range(num_clusters):\n",
    "        for j in range(i + 1, num_clusters):\n",
    "            cluster_i_points = X[labels == unique_clusters[i]]\n",
    "            cluster_j_points = X[labels == unique_clusters[j]]\n",
    "            intercluster_dist = np.min(cdist(cluster_i_points, cluster_j_points))\n",
    "            if intercluster_dist < min_intercluster_dist:\n",
    "                min_intercluster_dist = intercluster_dist\n",
    "\n",
    "    # Calculate Dunn index\n",
    "    if max_intracluster_dist == 0:  # Handle case where all clusters have single points\n",
    "        return 0  # or any other appropriate value\n",
    "    else:\n",
    "        return min_intercluster_dist / max_intracluster_dist\n",
    "    \n",
    "def compute_betacv(X, model):\n",
    "    if isinstance(model, KMeans):\n",
    "        labels = model.labels_\n",
    "    elif isinstance(model, GaussianMixture):\n",
    "        labels = model.predict(X)\n",
    "    elif isinstance(model, KMedoids):\n",
    "        labels = model.labels_\n",
    "\n",
    "    # Calculate pairwise distances\n",
    "    pairwise_dists = pairwise_distances(X)\n",
    "    \n",
    "    # Calculate intra-cluster distances (average distance within the same cluster)\n",
    "    intra_cluster_distances = []\n",
    "    for label in np.unique(labels):\n",
    "        cluster_points = X[labels == label]\n",
    "        intra_cluster_distances.append(np.mean(pairwise_distances(cluster_points)))\n",
    "    \n",
    "    # Calculate inter-cluster distances (average distance between different clusters)\n",
    "    inter_cluster_distances = []\n",
    "    for i, label1 in enumerate(np.unique(labels)):\n",
    "        for j, label2 in enumerate(np.unique(labels)):\n",
    "            if label1 != label2:\n",
    "                cluster1_points = X[labels == label1]\n",
    "                cluster2_points = X[labels == label2]\n",
    "                inter_cluster_distances.append(np.mean(pairwise_distances(np.concatenate([cluster1_points, cluster2_points]))))\n",
    "    \n",
    "    # BetaCV is the ratio of intra-cluster distance mean to inter-cluster distance mean\n",
    "    beta_cv = np.mean(intra_cluster_distances) / np.mean(inter_cluster_distances) if np.mean(inter_cluster_distances) != 0 else np.inf\n",
    "    return beta_cv\n",
    "\n",
    "def compute_hubert_statistic(X, model):\n",
    "    # Get cluster labels\n",
    "    if hasattr(model, 'labels_'):\n",
    "        labels = model.labels_\n",
    "    elif hasattr(model, 'predict'):\n",
    "        labels = model.predict(X)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported clustering model\")\n",
    "    \n",
    "    # Compute pairwise distances\n",
    "    dist_matrix = squareform(pdist(X))\n",
    "    \n",
    "    # Create binary similarity matrix\n",
    "    n = X.shape[0]\n",
    "    similarity_matrix = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            similarity_matrix[i,j] = 1 if labels[i] == labels[j] else 0\n",
    "    \n",
    "    # Extract upper triangular indices\n",
    "    mask = np.triu_indices(n, k=1)\n",
    "    \n",
    "    # Compute Pearson correlation\n",
    "    dist_vector = dist_matrix[mask]\n",
    "    similarity_vector = similarity_matrix[mask]\n",
    "    \n",
    "    # Compute correlation\n",
    "    correlation, _ = pearsonr(dist_vector, similarity_vector)\n",
    "    \n",
    "    return correlation\n",
    "\n",
    "def plot_clusters(X, model, model_name, image_path):\n",
    "    # Reduce data to 2D for visualization\n",
    "    pca = PCA(n_components=2)\n",
    "    X_2d = pca.fit_transform(X)\n",
    "    \n",
    "    labels = None\n",
    "    if model_name == \"K-Means\":\n",
    "        centers = model.cluster_centers_\n",
    "        labels = model.labels_\n",
    "    elif model_name == \"K-Medoids\":\n",
    "        centers = model.cluster_centers_\n",
    "        labels = model.labels_\n",
    "    elif model_name == \"EM-Clustering (GMM)\":\n",
    "        # For GMM, the centers are the means of the Gaussian components\n",
    "        centers = model.means_\n",
    "        labels = model.predict(X)\n",
    "\n",
    "    k = len(centers)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    # sns.scatterplot(x=X_2d[:, 0], y=X_2d[:, 1], hue=model.labels_, palette=\"Set2\", s=100, alpha=0.7, edgecolor='black')\n",
    "    scatter = sns.scatterplot(\n",
    "        x=X_2d[:, 0], \n",
    "        y=X_2d[:, 1], \n",
    "        hue=labels,\n",
    "        palette=\"Set2\", \n",
    "        s=100, \n",
    "        alpha=0.7, \n",
    "        edgecolor='black'\n",
    "    )\n",
    "\n",
    "    # Project centers to the 2D PCA space\n",
    "    centers_2d = pca.transform(centers)\n",
    "\n",
    "    # plt.scatter(centers_2d[:, 0], centers_2d[:, 1], c='red', marker='X', s=200, label=\"Cluster Centers\")\n",
    "    plt.scatter(\n",
    "        centers_2d[:, 0], \n",
    "        centers_2d[:, 1], \n",
    "        c='red', \n",
    "        marker='X', \n",
    "        s=200, \n",
    "        label=\"Cluster Centers\"\n",
    "    )\n",
    "    \n",
    "    plt.title(f\"{model_name} Clustering with Cluster Centers\")\n",
    "    plt.xlabel(\"Principal Component 1\")\n",
    "    plt.ylabel(\"Principal Component 2\")\n",
    "    plt.legend(title=\"Clusters\", title_fontsize=12, loc=\"best\", fontsize=10)\n",
    "    plt.grid(True, alpha=0.5)\n",
    "    \n",
    "    if os.path.exists(image_path) == False:\n",
    "        os.makedirs(image_path)\n",
    "    plot_name = os.path.join(image_path, f\"{model_name}_clustering_{k}.png\")\n",
    "    print(f\"Cluster plot saved as: {plot_name}\")\n",
    "    plt.savefig(plot_name)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform and evaluate all clustering algorithms\n",
    "def clustering_analysis(X, k, image_path):\n",
    "    results = []\n",
    "\n",
    "    # K-means\n",
    "    kmeans = k_means_clustering(X, k)\n",
    "    sse_kmeans = compute_sse(X, kmeans)\n",
    "    silhouette_kmeans = compute_silhouette(X, kmeans)\n",
    "    dunn_kmeans = compute_dunn_index(X, kmeans.labels_)\n",
    "    hubert_kmeans = compute_hubert_statistic(X, kmeans)\n",
    "    betacv_kmeans = compute_betacv(X, kmeans)\n",
    "    plot_clusters(X, kmeans, \"K-Means\", image_path)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": \"K-Means\",\n",
    "        \"K\": k,\n",
    "        \"SSE\": sse_kmeans,\n",
    "        \"Silhouette\": silhouette_kmeans,\n",
    "        \"Dunn's Index\": dunn_kmeans,\n",
    "        \"Hubert's Statistic\": hubert_kmeans,\n",
    "        \"BetaCV\": betacv_kmeans\n",
    "    })\n",
    "\n",
    "    # EM-Clustering (GMM)\n",
    "    gmm = em_clustering(X, k)\n",
    "    labels = gmm.predict(X)\n",
    "    sse_gmm = compute_sse(X, gmm)\n",
    "    silhouette_gmm = compute_silhouette(X, gmm)\n",
    "    dunn_gmm = compute_dunn_index(X, labels)\n",
    "    hubert_gmm = compute_hubert_statistic(X, gmm)\n",
    "    betacv_gmm = compute_betacv(X, gmm)\n",
    "    plot_clusters(X, gmm, \"EM-Clustering (GMM)\", image_path)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": \"EM-Clustering (GMM)\",\n",
    "        \"K\": k,\n",
    "        \"SSE\": sse_gmm,\n",
    "        \"Silhouette\": silhouette_gmm,\n",
    "        \"Dunn's Index\": dunn_gmm,\n",
    "        \"Hubert's Statistic\": hubert_gmm,\n",
    "        \"BetaCV\": betacv_gmm\n",
    "    })\n",
    "\n",
    "    # K-medoids\n",
    "    kmedoids_instance = k_medoids_clustering(X, k)\n",
    "    sse_kmedoids = compute_sse(X, kmedoids_instance)\n",
    "    silhouette_kmedoids = compute_silhouette(X, kmedoids_instance)\n",
    "    dunn_kmedoids = compute_dunn_index(X, kmedoids_instance.labels_)\n",
    "    hubert_kmedoids = compute_hubert_statistic(X, kmedoids_instance)\n",
    "    betacv_kmedoids = compute_betacv(X, kmedoids_instance)\n",
    "    plot_clusters(X, kmedoids_instance, \"K-Medoids\", image_path)\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": \"K-Medoids\",\n",
    "        \"K\": k,\n",
    "        \"SSE\": sse_kmedoids,\n",
    "        \"Silhouette\": silhouette_kmedoids,\n",
    "        \"Dunn's Index\": dunn_kmedoids,\n",
    "        \"Hubert's Statistic\": hubert_kmedoids,\n",
    "        \"BetaCV\": betacv_kmedoids\n",
    "    })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the models on original dataset\n",
    "\n",
    "results_original_2 = clustering_analysis(X_scaled, 2, \"./original_clustering_images\")\n",
    "results_original_4 = clustering_analysis(X_scaled, 4, \"./original_clustering_images\")\n",
    "results_original_all = pd.concat([results_original_2, results_original_4], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Clustering Analysis on Original Dataset\\n\")\n",
    "print(tabulate(results_original_all, headers=\"keys\", tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the models on PCA dataset\n",
    "\n",
    "results_pca_2 = clustering_analysis(X_train_pca, 2, \"./pca_clustering_images\")\n",
    "results_pca_4 = clustering_analysis(X_train_pca, 4, \"./pca_clustering_images\")\n",
    "results_pca_all = pd.concat([results_pca_2, results_pca_4], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Clustering Analysis on PCA Dataset\\n\")\n",
    "print(tabulate(results_pca_all, headers=\"keys\", tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
