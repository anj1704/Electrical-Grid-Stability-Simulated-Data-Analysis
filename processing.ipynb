{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> CS F320 Foundations of Data Science <center>\n",
    "\n",
    "## <center> Assignment <center>\n",
    "\n",
    "***\n",
    "\n",
    "### Group 8\n",
    "\n",
    "#### 1. 2022A7PS0145P - Armaan Gupta\n",
    "#### 2. 2022A7PS0065P - Animish Tiwari\n",
    "#### 3. 2022A7PS0164P - Anjaneya Bajaj\n",
    "#### 4. 2022A7PS0120P - Aryan Jain\n",
    "\n",
    "***\n",
    "\n",
    "#### Dataset : [Electrical Grid Stability Simulated Data](https://archive.ics.uci.edu/dataset/471/electrical+grid+stability+simulated+data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, precision_score, recall_score, f1_score, silhouette_score, pairwise_distances, pairwise_distances_argmin_min, adjusted_rand_score\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from ngboost import NGBRegressor\n",
    "from tabulate import tabulate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn_extra.cluster import KMedoids\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import pearsonr\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in the dataset and pre-processing\n",
    "\n",
    "- We will first load in the dataset and take a look at the first few rows to understand the data better.\n",
    "- We will then check for any missing values - there are none.\n",
    "- As per the question, we will drop categorical columns - there are None.\n",
    "- Eliminating outliers - any value that is more than 3 standard deviations away from the mean will be considered an outlier and will be removed.\n",
    "- Making plots to visualize the data distributions.\n",
    "- Seperating the two target variables one for classification and one for regression.\n",
    "- Splitting the data into training and testing sets.\n",
    "- Applying PCA, taking 10 principal components to account for >95% variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "electrical_grid_stability_simulated_data = fetch_ucirepo(id=471) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = electrical_grid_stability_simulated_data.data.features \n",
    "y = electrical_grid_stability_simulated_data.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(electrical_grid_stability_simulated_data.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(electrical_grid_stability_simulated_data.variables) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution of all numeric columns\n",
    "\n",
    "numeric_columns = df.drop(columns=['stab', 'stabf']).columns\n",
    "\n",
    "num_plots = len(numeric_columns)\n",
    "num_cols = 3\n",
    "num_rows = (num_plots // num_cols) + (1 if num_plots % num_cols != 0 else 0) \n",
    "\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(16, 6*num_rows))\n",
    "axes = axes.flatten()  \n",
    "\n",
    "for i, col in enumerate(numeric_columns):\n",
    "    sns.histplot(df[col], kde=True, ax=axes[i])\n",
    "    axes[i].set_title(f'Distribution of {col}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for variable 'stab'\n",
    "\n",
    "sns.histplot(df['stab'], kde=True)\n",
    "plt.title('Distribution of stab')\n",
    "plt.xlabel('stab')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for variable 'stabf'\n",
    "\n",
    "sns.countplot(x='stabf', data=df)\n",
    "plt.title('Distribution of stabf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into features and target\n",
    "\n",
    "X = df.drop(['stab', 'stabf'], axis=1)\n",
    "y = df['stab']\n",
    "y_classification = df['stabf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing outliers in all columns\n",
    "\n",
    "X = X[(np.abs(stats.zscore(X)) < 3).all(axis=1)] \n",
    "y = y[(np.abs(stats.zscore(y)) < 3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the train and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_classification, X_test_classification, y_train_classification, y_test_classification = train_test_split(X, y_classification, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-Score transformation\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# PCA \n",
    "\n",
    "# pca = PCA(n_components=3)\n",
    "pca = PCA()\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-Score transformation\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_classification_scaled = scaler.fit_transform(X_train_classification)\n",
    "X_test_classification_scaled = scaler.transform(X_test_classification)\n",
    "\n",
    "# PCA \n",
    "\n",
    "# pca = PCA(n_components=3)\n",
    "pca = PCA()\n",
    "X_train_classification_pca = pca.fit_transform(X_train_classification_scaled)\n",
    "X_test_classification_pca = pca.transform(X_test_classification_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explained variance ratio\n",
    "\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "# Plotting scree plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, len(explained_variance) + 1), explained_variance, marker='o', linestyle='--')\n",
    "plt.title('Scree Plot')\n",
    "plt.xlabel('Principal Component')\n",
    "plt.ylabel('Explained Variance Ratio')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_variance = pca.explained_variance_ratio_.cumsum()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', linestyle='--')\n",
    "plt.title('Cumulative Explained Variance')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.axhline(y=0.95, color='r', linestyle='--', label='95% Variance')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on plots, extracting 10 principal components\n",
    "\n",
    "X_train_pca = X_train_pca[:, :10]\n",
    "X_test_pca = X_test_pca[:, :10]\n",
    "\n",
    "X_train_classification_pca = X_train_classification_pca[:, :10]\n",
    "X_test_classification_pca = X_test_classification_pca[:, :10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Models\n",
    "\n",
    "Applying various regression models and calculating RMSE and MAE for each model. Models applied :\n",
    "- Linear Regression\n",
    "- Random Forests\n",
    "- Extra Random Trees\n",
    "- AdaBoost\n",
    "- XGBoost\n",
    "- NGBoost\n",
    "- Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function for Optuna hyperparameter tuning\n",
    "def objective(trial, model_name, X_train, y_train):\n",
    "    if model_name == \"Linear Regression\":\n",
    "        model = LinearRegression()\n",
    "    elif model_name == \"Ridge Regression\":\n",
    "        model = Ridge(\n",
    "            alpha=trial.suggest_float(\"alpha\", 1e-4, 100.0, log=True),\n",
    "            max_iter=trial.suggest_int(\"max_iter\", 100, 2000)\n",
    "        )\n",
    "    elif model_name == \"Lasso Regression\":\n",
    "        model = Lasso(\n",
    "            alpha=trial.suggest_float(\"alpha\", 1e-4, 100.0, log=True),  \n",
    "            max_iter=trial.suggest_int(\"max_iter\", 100, 2000)           \n",
    "        )\n",
    "    elif model_name == \"Elastic Net\":\n",
    "        model = ElasticNet(\n",
    "            alpha=trial.suggest_float(\"alpha\", 1e-4, 100.0, log=True),  \n",
    "            l1_ratio=trial.suggest_float(\"l1_ratio\", 0.0, 1.0),         \n",
    "            max_iter=trial.suggest_int(\"max_iter\", 100, 2000)           \n",
    "        )\n",
    "    elif model_name == \"Random Forest\":\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=trial.suggest_int(\"n_estimators\", 50, 500),\n",
    "            max_depth=trial.suggest_int(\"max_depth\", 3, 20),\n",
    "            min_samples_split=trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "            min_samples_leaf=trial.suggest_int(\"min_samples_leaf\", 1, 20),\n",
    "            random_state=42,\n",
    "        )\n",
    "    elif model_name == \"Extra Trees\":\n",
    "        model = ExtraTreesRegressor(\n",
    "            n_estimators=trial.suggest_int(\"n_estimators\", 50, 500),\n",
    "            max_depth=trial.suggest_int(\"max_depth\", 3, 20),\n",
    "            min_samples_split=trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "            min_samples_leaf=trial.suggest_int(\"min_samples_leaf\", 1, 20),\n",
    "            random_state=42,\n",
    "        )\n",
    "    elif model_name == \"AdaBoost\":\n",
    "        model = AdaBoostRegressor(\n",
    "            n_estimators=trial.suggest_int(\"n_estimators\", 50, 500),\n",
    "            learning_rate=trial.suggest_float(\"learning_rate\", 0.001, 1.0),\n",
    "            random_state=42,\n",
    "        )\n",
    "    elif model_name == \"XGBoost\":\n",
    "        model = XGBRegressor(\n",
    "            n_estimators=trial.suggest_int(\"n_estimators\", 50, 500),\n",
    "            max_depth=trial.suggest_int(\"max_depth\", 3, 20),\n",
    "            learning_rate=trial.suggest_float(\"learning_rate\", 0.01, 1),\n",
    "            colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.5, 1.0),\n",
    "            random_state=42,\n",
    "            objective='reg:squarederror',\n",
    "        )\n",
    "    elif model_name == \"NGBoost\":\n",
    "        model = NGBRegressor(\n",
    "            n_estimators=trial.suggest_int(\"n_estimators\", 50, 500),\n",
    "            learning_rate=trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "            random_state=42,\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model_name}\")\n",
    "\n",
    "    # Cross-validation to evaluate performance\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\")\n",
    "    return np.sqrt(-scores.mean())\n",
    "\n",
    "# Function to tune models using Optuna\n",
    "def tune_model(model_name, X_train, y_train):\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(lambda trial: objective(trial, model_name, X_train, y_train), n_trials=20)\n",
    "    return study.best_params, study.best_value\n",
    "\n",
    "# Function to train models with the best hyperparameters\n",
    "def train_model_with_best_params(model_name, best_params, X_train, y_train):\n",
    "    if model_name == \"Linear Regression\":\n",
    "        model = LinearRegression()\n",
    "    elif model_name == \"Ridge Regression\":\n",
    "        model = Ridge(**best_params)\n",
    "    elif model_name == \"Lasso Regression\":\n",
    "        model = Lasso(**best_params)\n",
    "    elif model_name == \"Elastic Net\":\n",
    "        model = ElasticNet(**best_params)\n",
    "    elif model_name == \"Random Forest\":\n",
    "        model = RandomForestRegressor(**best_params)\n",
    "    elif model_name == \"Extra Trees\":\n",
    "        model = ExtraTreesRegressor(**best_params)\n",
    "    elif model_name == \"AdaBoost\":\n",
    "        model = AdaBoostRegressor(**best_params)\n",
    "    elif model_name == \"XGBoost\":\n",
    "        model = XGBRegressor(**best_params)\n",
    "    elif model_name == \"NGBoost\":\n",
    "        model = NGBRegressor(**best_params)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model_name}\")\n",
    "    \n",
    "    print(f\"Training {model_name} with best hyperparameters...\")\n",
    "    print(f\"Best hyperparameters: {best_params}\")\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Train models with optimized parameters and evaluate them\n",
    "def regression_models_optimized(X_train, X_test, y_train, y_test, models):\n",
    "    model_results = []\n",
    "    model_params = []\n",
    "    for model_name in models:\n",
    "        print(f\"Tuning hyperparameters for {model_name}...\")\n",
    "        best_params, best_score = tune_model(model_name, X_train, y_train)\n",
    "        print(f\"Best parameters for {model_name}: {best_params}\")\n",
    "        \n",
    "        # Train the model with the best parameters\n",
    "        tuned_model = train_model_with_best_params(model_name, best_params, X_train, y_train)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        y_pred = tuned_model.predict(X_test)\n",
    "        \n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        \n",
    "        model_results.append({\"Model\": model_name, \"RMSE\": rmse, \"MAE\": mae})\n",
    "        model_params.append({\"Model\": model_name, \"Best Parameters\": best_params})\n",
    "    \n",
    "    results_df = pd.DataFrame(model_results)\n",
    "    params_df = pd.DataFrame(model_params)\n",
    "    return results_df, params_df\n",
    "\n",
    "models = [\n",
    "    \"Linear Regression\",\n",
    "    \"Ridge Regression\",\n",
    "    \"Lasso Regression\",\n",
    "    \"Elastic Net\",\n",
    "    \"Random Forest\",\n",
    "    \"Extra Trees\",\n",
    "    \"AdaBoost\",\n",
    "    \"XGBoost\",\n",
    "    \"NGBoost\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate models with optimized hyperparameters\n",
    "results_original, params_original = regression_models_optimized(X_train, X_test, y_train, y_test, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pca, params_pca = regression_models_optimized(X_train_pca, X_test_pca, y_train, y_test, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Regression Models Evaluation on Original Dataset\\n\")\n",
    "print(tabulate(results_original, headers=[\"Model\", \"RMSE\", \"MAE\"], tablefmt=\"grid\"))\n",
    "print(\"\\nBest Hyperparameters for Original Dataset\\n\")\n",
    "print(tabulate(params_original, headers=\"keys\", tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Regresssion Models Evaluation on PCA Dataset\\n\")\n",
    "print(tabulate(results_pca, headers=[\"Model\", \"RMSE\", \"MAE\"], tablefmt=\"grid\"))\n",
    "print(\"\\nBest Hyperparameters for PCA Dataset\\n\")\n",
    "print(tabulate(params_pca, headers=\"keys\", tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Models\n",
    "\n",
    "Applying various classification models and calculating accuracy, precision, recall and F1-score for each model. Models applied :\n",
    "- Logistic Regression\n",
    "- Naive Bayes\n",
    "- KNN\n",
    "- Linear SVM\n",
    "- Kernel SVM\n",
    "- Decision Trees\n",
    "- 2 Layer Fully Connected Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function for Optuna hyperparameter tuning (Classification)\n",
    "def objective(trial, model_name, X_train, y_train):\n",
    "    if model_name == \"Logistic Regression with L1 Regularization\":\n",
    "        model = LogisticRegression(\n",
    "            penalty=\"l1\",\n",
    "            solver=\"liblinear\",  # 'liblinear' supports L1 regularization\n",
    "            C=trial.suggest_float(\"C\", 1e-4, 10.0, log=True),\n",
    "            max_iter=trial.suggest_int(\"max_iter\", 100, 2000),\n",
    "            random_state=42,\n",
    "        )\n",
    "    elif model_name == \"Logistic Regression with L2 Regularization\":\n",
    "        model = LogisticRegression(\n",
    "            penalty=\"l2\",\n",
    "            solver=\"lbfgs\",\n",
    "            C=trial.suggest_float(\"C\", 1e-4, 10.0, log=True),\n",
    "            max_iter=trial.suggest_int(\"max_iter\", 100, 2000),\n",
    "            random_state=42,\n",
    "        )\n",
    "    elif model_name == \"Logistic Regression with Elastic Net Regularization\":\n",
    "        model = LogisticRegression(\n",
    "            penalty=\"elasticnet\",\n",
    "            solver=\"saga\",  # 'saga' supports Elastic Net\n",
    "            C=trial.suggest_float(\"C\", 1e-4, 10.0, log=True),\n",
    "            l1_ratio=trial.suggest_float(\"l1_ratio\", 0.0, 1.0),\n",
    "            max_iter=trial.suggest_int(\"max_iter\", 100, 2000),\n",
    "            random_state=42,\n",
    "        )\n",
    "    elif model_name == \"Gaussian Naive Bayes\":\n",
    "        model = GaussianNB()\n",
    "    elif model_name == \"K-Nearest Neighbors\":\n",
    "        model = KNeighborsClassifier(\n",
    "            n_neighbors=trial.suggest_int(\"n_neighbors\", 1, 50),\n",
    "            weights=trial.suggest_categorical(\"weights\", [\"uniform\", \"distance\"]),\n",
    "            p=trial.suggest_int(\"p\", 1, 2),  # Minkowski metric: 1 for Manhattan, 2 for Euclidean\n",
    "        )\n",
    "    elif model_name == \"Linear SVM\":\n",
    "        model = SVC(\n",
    "            kernel=\"linear\",\n",
    "            C=trial.suggest_float(\"C\", 1e-4, 10.0, log=True),\n",
    "            random_state=42,\n",
    "        )\n",
    "    elif model_name == \"Kernel SVM\":\n",
    "        model = SVC(\n",
    "            kernel=\"rbf\",\n",
    "            C=trial.suggest_float(\"C\", 1e-4, 10.0, log=True),\n",
    "            gamma=trial.suggest_float(\"gamma\", 1e-4, 10.0, log=True),\n",
    "            random_state=42,\n",
    "        )\n",
    "    elif model_name == \"Decision Tree\":\n",
    "        model = DecisionTreeClassifier(\n",
    "            max_depth=trial.suggest_int(\"max_depth\", 1, 20),\n",
    "            min_samples_split=trial.suggest_int(\"min_samples_split\", 2, 20),\n",
    "            min_samples_leaf=trial.suggest_int(\"min_samples_leaf\", 1, 20),\n",
    "            random_state=42,\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model_name}\")\n",
    "\n",
    "    # Cross-validation to evaluate performance\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "    return scores.mean()\n",
    "\n",
    "# Function to tune models using Optuna\n",
    "def tune_model(model_name, X_train, y_train):\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(lambda trial: objective(trial, model_name, X_train, y_train), n_trials=20)\n",
    "    return study.best_params, study.best_value\n",
    "\n",
    "# Function to train models with the best hyperparameters\n",
    "def train_model_with_best_params(model_name, best_params, X_train, y_train):\n",
    "    if model_name == \"Logistic Regression with L1 Regularization\":\n",
    "        model = LogisticRegression(penalty=\"l1\", solver=\"liblinear\", random_state=42, **best_params)\n",
    "    elif model_name == \"Logistic Regression with L2 Regularization\":\n",
    "        model = LogisticRegression(penalty=\"l2\", solver=\"lbfgs\", random_state=42, **best_params)\n",
    "    elif model_name == \"Logistic Regression with Elastic Net Regularization\":\n",
    "        model = LogisticRegression(penalty=\"elasticnet\", solver=\"saga\", random_state=42, **best_params)\n",
    "    elif model_name == \"Gaussian Naive Bayes\":\n",
    "        model = GaussianNB()\n",
    "    elif model_name == \"K-Nearest Neighbors\":\n",
    "        model = KNeighborsClassifier(**best_params)\n",
    "    elif model_name == \"Linear SVM\":\n",
    "        model = SVC(kernel=\"linear\", random_state=42, **best_params)\n",
    "    elif model_name == \"Kernel SVM\":\n",
    "        model = SVC(kernel=\"rbf\", random_state=42, **best_params)\n",
    "    elif model_name == \"Decision Tree\":\n",
    "        model = DecisionTreeClassifier(random_state=42, **best_params)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model_name}\")\n",
    "    \n",
    "    print(f\"Training {model_name} with best hyperparameters...\")\n",
    "    print(f\"Best hyperparameters: {best_params}\")\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Train models with optimized parameters and evaluate them\n",
    "def classification_models_optimized(X_train, X_test, y_train, y_test, models):\n",
    "    model_results = []\n",
    "    model_params = []\n",
    "    for model_name in models:\n",
    "        print(f\"Tuning hyperparameters for {model_name}...\")\n",
    "        best_params, best_score = tune_model(model_name, X_train, y_train)\n",
    "        print(f\"Best parameters for {model_name}: {best_params}\")\n",
    "        \n",
    "        # Train the model with the best parameters\n",
    "        tuned_model = train_model_with_best_params(model_name, best_params, X_train, y_train)\n",
    "        \n",
    "        # Evaluate the model\n",
    "        y_pred = tuned_model.predict(X_test)\n",
    "        \n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "        recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "        f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "    \n",
    "        model_results.append({\"Model\": model_name, \"Accuracy\": accuracy, \"Precision\": precision, \"Recall\": recall, \"F1-Score\": f1})\n",
    "        model_params.append({\"Model\": model_name, \"Best Parameters\": best_params})\n",
    "    \n",
    "    results_df = pd.DataFrame(model_results)\n",
    "    params_df = pd.DataFrame(model_params)\n",
    "    return results_df, params_df\n",
    "\n",
    "# Define models for classification\n",
    "models = [\n",
    "    \"Logistic Regression with L1 Regularization\",\n",
    "    \"Logistic Regression with L2 Regularization\",\n",
    "    \"Logistic Regression with Elastic Net Regularization\",\n",
    "    \"Gaussian Naive Bayes\",\n",
    "    \"K-Nearest Neighbors\",\n",
    "    \"Linear SVM\",\n",
    "    \"Kernel SVM\",\n",
    "    \"Decision Tree\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_original, params_original = classification_models_optimized(X_train_classification, X_test_classification, y_train_classification, y_test_classification, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_pca, params_pca = classification_models_optimized(X_train_classification_pca, X_test_classification_pca, y_train_classification, y_test_classification, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Neural Network\n",
    "\n",
    "# class NN(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size, output_size):\n",
    "#         super(NN, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "#         self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = torch.relu(self.fc1(x))\n",
    "#         x = self.fc2(x)\n",
    "#         return x\n",
    "\n",
    "# # Train function\n",
    "# def train_model(model, X_train, y_train, criterion, optimizer, batch_size, num_epochs):\n",
    "#     model.train()\n",
    "#     dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "#     data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         for batch_X, batch_y in data_loader:\n",
    "#             # Forward pass\n",
    "#             outputs = model(batch_X)\n",
    "#             loss = criterion(outputs, batch_y)\n",
    "\n",
    "#             # Backward pass and optimization\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#             if (epoch + 1) % 10 == 0:\n",
    "#                 print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "# # Test function\n",
    "# def test_model(model, X_test, y_test):\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         y_pred = model(X_test).argmax(dim=1).numpy()\n",
    "\n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
    "#     recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
    "#     f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "#     return accuracy, precision, recall, f1\n",
    "\n",
    "# # Optuna objective function for hyperparameter tuning\n",
    "# def objective(trial, X_train, y_train, X_test, y_test, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor):\n",
    "#     input_size = X_train.shape[1]\n",
    "#     output_size = len(y_train.unique())\n",
    "#     hidden_size = trial.suggest_int(\"hidden_size\", 16, 128, step=16)\n",
    "#     learning_rate = trial.suggest_float(\"lr\", 1e-4, 1e-1, log=True)\n",
    "#     batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 128])\n",
    "#     num_epochs = trial.suggest_int(\"num_epochs\", 50, 300, step=50)\n",
    "\n",
    "#     # Initialize the model, criterion, and optimizer\n",
    "#     model = NN(input_size, hidden_size, output_size)\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "#     # Train the model\n",
    "#     train_model(model, X_train_tensor, y_train_tensor, criterion, optimizer, batch_size, num_epochs)\n",
    "\n",
    "#     # Test the model\n",
    "#     accuracy, _, _, _ = test_model(model, X_test_tensor, y_test_tensor)\n",
    "\n",
    "#     return accuracy\n",
    "\n",
    "# # Function to tune and evaluate the neural network\n",
    "# def tune_nn(X_train, y_train, X_test, y_test, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, results, best_params_df):\n",
    "#     study = optuna.create_study(direction=\"maximize\")\n",
    "#     study.optimize(lambda trial: objective(trial, X_train, y_train, X_test, y_test, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor), n_trials=50)\n",
    "\n",
    "#     best_params = study.best_params\n",
    "#     print(\"Best hyperparameters:\", best_params)\n",
    "\n",
    "#     # Train the best model\n",
    "#     input_size = X_train.shape[1]\n",
    "#     output_size = len(y_train.unique())\n",
    "#     model = NN(input_size, best_params[\"hidden_size\"], output_size)\n",
    "#     criterion = nn.CrossEntropyLoss()\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=best_params[\"lr\"])\n",
    "\n",
    "#     # Train and evaluate the model\n",
    "#     train_model(model, X_train_tensor, y_train_tensor, criterion, optimizer, best_params[\"batch_size\"], best_params[\"num_epochs\"])\n",
    "#     accuracy, precision, recall, f1 = test_model(model, X_test_tensor, y_test_tensor)\n",
    "\n",
    "#     print(\"Final Model Metrics:\")\n",
    "#     print(f\"Accuracy: {accuracy:.2f}\")\n",
    "#     print(f\"Precision: {precision:.2f}\")\n",
    "#     print(f\"Recall: {recall:.2f}\")\n",
    "#     print(f\"F1-Score: {f1:.2f}\")\n",
    "\n",
    "#     results.loc[len(results)] = [\"Neural Network\", accuracy, precision, recall, f1]\n",
    "#     best_params_df.loc[len(best_params_df)] = [\"Neural Network\", best_params]\n",
    "#     return model, best_params\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(BinaryNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return self.sigmoid(x)\n",
    "\n",
    "def train_model(model, X_train, y_train, criterion, optimizer, batch_size, num_epochs):\n",
    "    model.train()\n",
    "    dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_X, batch_y in data_loader:\n",
    "            # Forward pass\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs.squeeze(), batch_y.float())\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (epoch + 1) % 10 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "def test_model(model, X_test, y_test):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = (model(X_test).squeeze() > 0.5).numpy()\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "def objective(trial, X_train, y_train, X_test, y_test, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor):\n",
    "    input_size = X_train.shape[1]\n",
    "    hidden_size = trial.suggest_int(\"hidden_size\", 16, 128, step=16)\n",
    "    learning_rate = trial.suggest_float(\"lr\", 1e-4, 1e-1, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 128])\n",
    "    num_epochs = trial.suggest_int(\"num_epochs\", 50, 300, step=50)\n",
    "    \n",
    "    # Initialize the model, criterion, and optimizer\n",
    "    model = BinaryNN(input_size, hidden_size)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Train the model\n",
    "    train_model(model, X_train_tensor, y_train_tensor, criterion, optimizer, batch_size, num_epochs)\n",
    "    \n",
    "    # Test the model\n",
    "    accuracy, _, _, _ = test_model(model, X_test_tensor, y_test_tensor)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "def tune_nn(X_train, y_train, X_test, y_test, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, results, best_params_df):\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(lambda trial: objective(trial, X_train, y_train, X_test, y_test, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor), n_trials=20)\n",
    "    \n",
    "    best_params = study.best_params\n",
    "    print(\"Best hyperparameters:\", best_params)\n",
    "    \n",
    "    # Train the best model\n",
    "    input_size = X_train.shape[1]\n",
    "    model = BinaryNN(input_size, best_params[\"hidden_size\"])\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=best_params[\"lr\"])\n",
    "    \n",
    "    # Train and evaluate the model\n",
    "    train_model(model, X_train_tensor, y_train_tensor, criterion, optimizer, best_params[\"batch_size\"], best_params[\"num_epochs\"])\n",
    "    accuracy, precision, recall, f1 = test_model(model, X_test_tensor, y_test_tensor)\n",
    "    \n",
    "    print(\"Final Model Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(f\"Precision: {precision:.2f}\")\n",
    "    print(f\"Recall: {recall:.2f}\")\n",
    "    print(f\"F1-Score: {f1:.2f}\")\n",
    "    \n",
    "    results.loc[len(results)] = [\"Neural Network\", accuracy, precision, recall, f1]\n",
    "    best_params_df.loc[len(best_params_df)] = [\"Neural Network\", best_params]\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to tensors\n",
    "X_train_tensor = torch.tensor(X_train_classification.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_classification.to_numpy(), dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test_classification.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_classification.to_numpy(), dtype=torch.long)\n",
    "\n",
    "tune_nn(X_train_classification, y_train_classification, X_test_classification, y_test_classification, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, results_original, params_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to tensors\n",
    "X_train_tensor = torch.tensor(X_train_classification_pca.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_classification.to_numpy(), dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test_classification_pca.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_classification.to_numpy(), dtype=torch.long)\n",
    "\n",
    "tune_nn(X_train_classification, y_train_classification, X_test_classification, y_test_classification, X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor, results_pca, params_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Models Evaluation on Original Dataset\\n\")\n",
    "print(tabulate(results_original, headers=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"], tablefmt=\"grid\"))\n",
    "print(\"\\nBest Hyperparameters for Original Dataset\\n\")\n",
    "print(tabulate(params_original, headers=\"keys\", tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Classification Models Evaluation on PCA Dataset\\n\")\n",
    "print(tabulate(results_pca, headers=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\"], tablefmt=\"grid\"))\n",
    "print(\"\\nBest Hyperparameters for PCA Dataset\\n\")\n",
    "print(tabulate(params_pca, headers=\"keys\", tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Models\n",
    "\n",
    "Scaling the original data.\n",
    "Applying various clustering models and calculating SSE, Silhouette, BetaCV, Dunn’s Index and Hubert’s Statistic for each model. Models applied :\n",
    "- KMeans\n",
    "- EM Clustering\n",
    "- KMedoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data \n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means_clustering(X, k):\n",
    "    kmeans = KMeans(n_clusters=k, init=\"k-means++\", random_state=42)\n",
    "    kmeans.fit(X)\n",
    "\n",
    "    return kmeans\n",
    "\n",
    "def em_clustering(X, k):\n",
    "    gmm = GaussianMixture(n_components=k, init=\"k-means++\", random_state=42)\n",
    "    gmm.fit(X)\n",
    "\n",
    "    return gmm\n",
    "\n",
    "def k_medoids_clustering(X, k):\n",
    "    kmedoids = KMedoids(n_clusters=k, random_state=42)\n",
    "    kmedoids.fit(X)\n",
    "\n",
    "    return kmedoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_sse(X, model):\n",
    "    if isinstance(model, KMeans):\n",
    "        labels = model.labels_\n",
    "        centroids = model.cluster_centers_\n",
    "        sse = np.sum((X - centroids[labels]) ** 2)\n",
    "    elif isinstance(model, GaussianMixture):\n",
    "        labels = model.predict(X)\n",
    "        centroids = model.means_\n",
    "        sse = np.sum((X - centroids[labels]) ** 2)\n",
    "    elif isinstance(model, KMedoids):\n",
    "        labels = model.labels_\n",
    "        medoids = model.cluster_centers_\n",
    "        sse = np.sum((X - medoids[labels]) ** 2)\n",
    "    return sse\n",
    "\n",
    "def compute_silhouette(X, model):\n",
    "    if isinstance(model, KMeans):\n",
    "        labels = model.labels_\n",
    "    elif isinstance(model, GaussianMixture):\n",
    "        labels = model.predict(X)\n",
    "    elif isinstance(model, KMedoids):\n",
    "        labels = model.labels_\n",
    "    \n",
    "    return silhouette_score(X, labels)\n",
    "\n",
    "def compute_dunn_index(X, model):\n",
    "    if isinstance(model, KMeans):\n",
    "        labels = model.labels_\n",
    "    elif isinstance(model, GaussianMixture):\n",
    "        labels = model.predict(X)\n",
    "    elif isinstance(model, KMedoids):\n",
    "        labels = model.labels_\n",
    "\n",
    "    # Compute pairwise distances between points\n",
    "    pairwise_dists = pairwise_distances(X)\n",
    "\n",
    "    # Calculate intra-cluster distances (min distance within the same cluster)\n",
    "    intra_cluster_distances = []\n",
    "    for label in np.unique(labels):\n",
    "        cluster_points = X[labels == label]\n",
    "        if len(cluster_points) > 1:\n",
    "            intra_cluster_distances.append(np.min(pairwise_distances(cluster_points)))\n",
    "    min_intra_cluster_distance = np.min(intra_cluster_distances)\n",
    "\n",
    "    # Calculate inter-cluster distances (min distance between different clusters)\n",
    "    inter_cluster_distances = []\n",
    "    for i, label1 in enumerate(np.unique(labels)):\n",
    "        for j, label2 in enumerate(np.unique(labels)):\n",
    "            if label1 != label2:\n",
    "                cluster1_points = X[labels == label1]\n",
    "                cluster2_points = X[labels == label2]\n",
    "                inter_cluster_distances.append(np.min(pairwise_distances(np.concatenate([cluster1_points, cluster2_points]))))\n",
    "    max_inter_cluster_distance = np.max(inter_cluster_distances)\n",
    "\n",
    "    return min_intra_cluster_distance / max_inter_cluster_distance\n",
    "\n",
    "def compute_betacv(X, model):\n",
    "    if isinstance(model, KMeans):\n",
    "        labels = model.labels_\n",
    "    elif isinstance(model, GaussianMixture):\n",
    "        labels = model.predict(X)\n",
    "    elif isinstance(model, KMedoids):\n",
    "        labels = model.labels_\n",
    "\n",
    "    # Calculate pairwise distances\n",
    "    pairwise_dists = pairwise_distances(X)\n",
    "    \n",
    "    # Calculate intra-cluster distances (average distance within the same cluster)\n",
    "    intra_cluster_distances = []\n",
    "    for label in np.unique(labels):\n",
    "        cluster_points = X[labels == label]\n",
    "        intra_cluster_distances.append(np.mean(pairwise_distances(cluster_points)))\n",
    "    \n",
    "    # Calculate inter-cluster distances (average distance between different clusters)\n",
    "    inter_cluster_distances = []\n",
    "    for i, label1 in enumerate(np.unique(labels)):\n",
    "        for j, label2 in enumerate(np.unique(labels)):\n",
    "            if label1 != label2:\n",
    "                cluster1_points = X[labels == label1]\n",
    "                cluster2_points = X[labels == label2]\n",
    "                inter_cluster_distances.append(np.mean(pairwise_distances(np.concatenate([cluster1_points, cluster2_points]))))\n",
    "    \n",
    "    # BetaCV is the ratio of intra-cluster distance mean to inter-cluster distance mean\n",
    "    beta_cv = np.mean(intra_cluster_distances) / np.mean(inter_cluster_distances) if np.mean(inter_cluster_distances) != 0 else np.inf\n",
    "    return beta_cv\n",
    "\n",
    "def compute_hubert_statistic(X, model):\n",
    "    # Get cluster labels\n",
    "    if hasattr(model, 'labels_'):\n",
    "        labels = model.labels_\n",
    "    elif hasattr(model, 'predict'):\n",
    "        labels = model.predict(X)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported clustering model\")\n",
    "    \n",
    "    # Compute pairwise distances\n",
    "    dist_matrix = squareform(pdist(X))\n",
    "    \n",
    "    # Create binary similarity matrix\n",
    "    n = X.shape[0]\n",
    "    similarity_matrix = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            similarity_matrix[i,j] = 1 if labels[i] == labels[j] else 0\n",
    "    \n",
    "    # Extract upper triangular indices\n",
    "    mask = np.triu_indices(n, k=1)\n",
    "    \n",
    "    # Compute Pearson correlation\n",
    "    dist_vector = dist_matrix[mask]\n",
    "    similarity_vector = similarity_matrix[mask]\n",
    "    \n",
    "    # Compute correlation\n",
    "    correlation, _ = pearsonr(dist_vector, similarity_vector)\n",
    "    \n",
    "    return correlation\n",
    "\n",
    "def plot_clusters(X, model, model_name):\n",
    "    # Reduce data to 2D for visualization\n",
    "    pca = PCA(n_components=2)\n",
    "    X_2d = pca.fit_transform(X)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=X_2d[:, 0], y=X_2d[:, 1], hue=model.labels_, palette=\"Set2\", s=100, alpha=0.7, edgecolor='black')\n",
    "    \n",
    "    if model_name == \"K-Means\":\n",
    "        centers = model.cluster_centers_\n",
    "    elif model_name == \"K-Medoids\":\n",
    "        centers = X[model.get_medoids()]\n",
    "    elif model_name == \"EM-Clustering (GMM)\":\n",
    "        # For GMM, the centers are the means of the Gaussian components\n",
    "        centers = model.means_\n",
    "\n",
    "    # Project centers to the 2D PCA space\n",
    "    centers_2d = pca.transform(centers)\n",
    "    \n",
    "    plt.scatter(centers_2d[:, 0], centers_2d[:, 1], c='red', marker='X', s=200, label=\"Cluster Centers\")\n",
    "    \n",
    "    plt.title(f\"{model_name} Clustering with Cluster Centers\")\n",
    "    plt.xlabel(\"Principal Component 1\")\n",
    "    plt.ylabel(\"Principal Component 2\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform and evaluate all clustering algorithms\n",
    "def clustering_analysis(X, k):\n",
    "    results = []\n",
    "\n",
    "    # K-means\n",
    "    kmeans = k_means_clustering(X, k)\n",
    "    sse_kmeans = compute_sse(X, kmeans)\n",
    "    silhouette_kmeans = compute_silhouette(X, kmeans)\n",
    "    dunn_kmeans = compute_dunn_index(X, kmeans)\n",
    "    hubert_kmeans = compute_hubert_statistic(X, kmeans)\n",
    "    betacv_kmeans = compute_betacv(X, kmeans)\n",
    "    plot_clusters(X, kmeans.labels_, f\"K-Means Clustering (k={k})\")\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": \"K-Means\",\n",
    "        \"K\": k,\n",
    "        \"SSE\": sse_kmeans,\n",
    "        \"Silhouette\": silhouette_kmeans,\n",
    "        \"Dunn's Index\": dunn_kmeans,\n",
    "        \"Hubert's Statistic\": hubert_kmeans,\n",
    "        \"BetaCV\": betacv_kmeans\n",
    "    })\n",
    "\n",
    "    # EM-Clustering (GMM)\n",
    "    gmm = em_clustering(X, k)\n",
    "    sse_gmm = compute_sse(X, gmm)\n",
    "    silhouette_gmm = compute_silhouette(X, gmm)\n",
    "    dunn_gmm = compute_dunn_index(X, gmm)\n",
    "    hubert_gmm = compute_hubert_statistic(X, gmm)\n",
    "    betacv_gmm = compute_betacv(X, gmm)\n",
    "    plot_clusters(X, gmm.predict(X), f\"EM-Clustering (GMM) (k={k})\")\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": \"EM-Clustering (GMM)\",\n",
    "        \"K\": k,\n",
    "        \"SSE\": sse_gmm,\n",
    "        \"Silhouette\": silhouette_gmm,\n",
    "        \"Dunn's Index\": dunn_gmm,\n",
    "        \"Hubert's Statistic\": hubert_gmm,\n",
    "        \"BetaCV\": betacv_gmm\n",
    "    })\n",
    "\n",
    "    # K-medoids\n",
    "    kmedoids_instance = k_medoids_clustering(X, k)\n",
    "    sse_kmedoids = compute_sse(X, kmedoids_instance)\n",
    "    silhouette_kmedoids = compute_silhouette(X, kmedoids_instance)\n",
    "    dunn_kmedoids = compute_dunn_index(X, kmedoids_instance)\n",
    "    hubert_kmedoids = compute_hubert_statistic(X, kmedoids_instance)\n",
    "    betacv_kmedoids = compute_betacv(X, kmedoids_instance)\n",
    "    plot_clusters(X, kmedoids_instance.labels_, f\"K-Medoids Clustering (k={k})\")\n",
    "\n",
    "    results.append({\n",
    "        \"Model\": \"K-Medoids\",\n",
    "        \"K\": k,\n",
    "        \"SSE\": sse_kmedoids,\n",
    "        \"Silhouette\": silhouette_kmedoids,\n",
    "        \"Dunn's Index\": dunn_kmedoids,\n",
    "        \"Hubert's Statistic\": hubert_kmedoids,\n",
    "        \"BetaCV\": betacv_kmedoids\n",
    "    })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the models on original dataset\n",
    "\n",
    "results_original = clustering_analysis(X_scaled, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Clustering Analysis on Original Dataset\\n\")\n",
    "print(tabulate(results_original, headers=\"keys\", tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the models on PCA dataset\n",
    "\n",
    "results_pca = clustering_analysis(X_train_pca, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Clustering Analysis on PCA Dataset\\n\")\n",
    "print(tabulate(results_pca, headers=\"keys\", tablefmt=\"grid\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
